{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 4: Classificiation with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you'll be learning about how to use scikit-learn to perform text classificaiton.\n",
    "\n",
    "Commit and push this Jupyter Notebook (<code>ps4_classification.ipynb</code>) to GitHub by 11:59pm on Monday, September 28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The task: Classifying men and women by voice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The included file, `features.csv`, contains the mean pitch, mean intensity, and duration for each of the `.wav` files you worked with for the last problem set.\n",
    "\n",
    "In this problem set, you will investigate whether these features can help you to automatically determine whether the speaker is a man or a woman, using the machine learning library scikit-learn.\n",
    "\n",
    "First run the cell below to import the necessary libraries, some of which you might need to install. You'll know that they're missing from your installation of Python if you get errors when you run the code below. If you are admininstering your own installation of Python, use `pip3 install scikit-learn` and `pip3 install numpy`. If you're using Anaconda, install using the Anaconda library installation interface.\n",
    "\n",
    "Remember that in Jupyter Notebooks, to run the code in a cell, go up to the menu at the top and click `Run` or just hold down the `shift` key and then hit `return`.\n",
    "\n",
    "Also remember that if things are going crazy, go to `Kernel` then `Restart and clear output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changing anything\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've provided a file I created with parselmouth, using a script that I've included in this repo. \n",
    "\n",
    "Your job is to read in the file so that at the end you have (1) a numpy 2-D array of **floats** where each row is a person and each cell in the row is one of the three feature (mean pitch, mean energy, duration); and (2) a numpy 1-D array of **integers** that contains the class labels associated with each person (1 or 0, woman or man). <span style=\"color: red;\">**Don't forget to convert strings to floats or ints as you store the features in the target and data lists.**</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can just run this cell without changing anything.\n",
    "\n",
    "# Just to be helpful, I'm reading in the first line of the features.csv file\n",
    "# so you know that there are headers and what those headers are.\n",
    "\n",
    "# Open the file. You'll have to update the path to make it work on your machine.\n",
    "f = open(\"/Users/emilypx/Desktop/ps4/features.csv\")\n",
    "\n",
    "# Get the first line of the file, which is the headers indicated which\n",
    "# information is contained in each column.\n",
    "featureIDs = f.readline().rstrip().split(\",\")\n",
    "\n",
    "# Close the file\n",
    "f.close()\n",
    "\n",
    "print(\"The features are:\", featureIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here's where you write your code to read in the data.\n",
    "\n",
    "## Populate two variables: nparray and nptarget.\n",
    "\n",
    "# Class labels will be stored in nptarget (a 1D numpy array).\n",
    "    # This will be a list of 0's and 1's (integers).\n",
    "    # You will get these from the last field in the features.csv file.\n",
    "\n",
    "# Feature data will be stored in npdata (a 2D numpy array).\n",
    "    # This will be a 2D array. Each row represents a person.\n",
    "    # Each element in row is a feature value (pitch, energy, duration as floats).\n",
    "\n",
    "\n",
    "## You may read the file in yourself with the basic i/o library and .split(\",\")\n",
    "## or you can use the csv library, pandas read_cvs, or numpy genfromtxt. \n",
    "## The important thing is that you populate the target and data variables correctly\n",
    "## and that they end up as numpy arrays and not lists.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code below to see how many features and training vectors you have. It should print out\n",
    "\n",
    "```\n",
    "You have  462 training instances\n",
    "You have  3 features\n",
    "You have  462 class labels\n",
    "```\n",
    "\n",
    "If it doesn't print that out, you've done something wrong when reading in the file. You might want to restart the kernel and clear output, depending on how wrong it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"You have \", npdata.shape[0], \"training instances\")\n",
    "print(\"You have \", npdata.shape[1], \"features\")\n",
    "print(\"You have \", nptarget.shape[0], \"class labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, write code to count and print out the number of men (class id = 0) and the number of women (class id = 1) in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the number of men \n",
    "\n",
    "\n",
    "# print out the number of women\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Q1: Is this a balanced dataset? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your answer to Q1 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Q2: What is the majority baseline accuracy?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your answer to Q2 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it helps to visualize the data a bit before you start thinking about classification. The code below, which you do not need to modify, plots the values for women in blue and for men in red for each feature. The x axis is just the index of the row for that person, while the y axis is the feature value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can run this cell without modifying the code.\n",
    "\n",
    "# Create a separate nparray for each feature (pitch, intensity, and duration)\n",
    "pitch = npdata[:,0:1]\n",
    "intensity = npdata[:,1:2]\n",
    "duration = npdata[:,2:3]\n",
    "\n",
    "# Create a plot with three subplots\n",
    "fig, axs = plt.subplots(3, sharex=True)\n",
    "\n",
    "\n",
    "for i in range(len(npdata)):\n",
    "    if nptarget[i] == 0:\n",
    "        axs[0].plot(i,pitch[i], color=\"red\", marker=\".\")\n",
    "        axs[1].plot(i,intensity[i], color=\"red\", marker=\".\")\n",
    "        axs[2].plot(i,duration[i], color=\"red\", marker=\".\")\n",
    "    else:\n",
    "        axs[0].plot(i,pitch[i], color=\"blue\", marker=\".\")\n",
    "        axs[1].plot(i,intensity[i], color=\"blue\", marker=\".\")\n",
    "        axs[2].plot(i,duration[i], color=\"blue\", marker=\".\")\n",
    "\n",
    "axs[0].set_title(\"pitch\")\n",
    "axs[1].set_title(\"intensity\")\n",
    "axs[2].set_title(\"duration\")\n",
    "\n",
    "axs[0].set_ylabel(\"Hz\")\n",
    "axs[1].set_ylabel(\"dB\")\n",
    "axs[2].set_ylabel(\"sec\")\n",
    "\n",
    "\n",
    "fig.tight_layout(pad=1.0)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Q3: Based on the pictures above, what feature do you think will do the best job a separating men's voices from women's voices and why?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your answer to Q3 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification with cross validation\n",
    "\n",
    "Okay, let's do some classification! First we are going to just look at each feature one by one, and we'll use a Naive Bayes classifier. \n",
    "\n",
    "Remember, we can't train and test of the same data, so we'll be sure to use cross validation. Here's some code that will do this for you and print out some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# You can run this cell without modifying the code\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Select some scoring metrics\n",
    "scoring_metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Train a Naive Bayes model with 5-fold cross validation for the duration feature.\n",
    "scores = cross_validate(gnb, duration, nptarget, cv=5, scoring=scoring_metrics)\n",
    "\n",
    "# Print out each of the metrics for each of the 5 folds and their means.\n",
    "for score_name, score_value in scores.items():\n",
    "    print(score_name, score_value, np.mean(score_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the last few lines of code above as an example, build and train a model that uses only the **pitch** feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model with pitch and 5-fold cross validation\n",
    "\n",
    "\n",
    "# print out the model evaluation metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the last few lines of code above as an example, build and train a model that uses only the **intensity** feature. (Warning: You will get lots of warning messages!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model with intensity and 5-fold cross validation\n",
    "\n",
    "\n",
    "# print out the model evaluation metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the last few lines of code above as an example, build and train a model that uses **all three features**. (Hint: instead of `pitch`, `duration`, or `intensity` use `npdata`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model with all three features and 5-fold cross validation\n",
    "\n",
    "\n",
    "# print out the model evaluation metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying the code above as an example and using the documentation for <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validation.html\">cross_validation</a>, change the number of folds in the cross validation to 10 and use all three features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model with all three features but 10-fold CV\n",
    "\n",
    "\n",
    "# print out the evaluation metrics, as above\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Q4: What went wrong with the intensity feature? Why did you get all 0's for most of the metrics and all the error messages? What does this mean?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your answer to Q4 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q5. In the cell below comment on the accuracy, precision, recall, and F1 measure for each of the three features individually and the features together. How did the results compare to the majority baseline accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your answer to Q5 here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q6. Was there any noticeable difference with 10-fold vs. 5-fold cross validation? </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your answer to Q6 here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Swap out Naive Bayes for *two* other classifiers, such as a <a href=\"http://scikit-learn.org/stable/modules/tree.html\">decision tree</a>, a [random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), a [multilayer perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html), an SVM (use <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\">LinearSVC</a>), or <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">k-NN</a>. **You will need some additional imports, of course!**\n",
    "\n",
    "Use just 5 folds, and again print out the average accuracy, precision, recall, and F1 over the 5 folds. Refer to the linked documentation above to get the right syntax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some import statments that might be helpful for you.\n",
    "# Hint: If you get a warning about LinearSVC, increase the number of iterations.\n",
    "# Please consult the documentation for details about the necessary arguments.\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "## See the documentation for details.\n",
    "\n",
    "\n",
    "\n",
    "## Enter your code for cross validation (5 folds) with your first classifier here.\n",
    "\n",
    "\n",
    "\n",
    "## Enter your code for cross validation (5 folds) with your second classifier here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q7. In the cell below comment on the precision, recall, and F1 measure (all three!) of these two other classifiers. Are they better or worse, on average, than the naive Bayes classifier you used above?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your answer to Q7 here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing on a held-out set of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you want to hold out some of your data for testing, and use the rest for training. Here's how you can do that. Run it too what happens, and REMEMBER HOW THIS IS DONE, since you'll be doing this sort of thing in future labs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can run this cell without modifying the code\n",
    "\n",
    "\n",
    "# randomly select a subset of your data (size = 10)\n",
    "testid = [1, 1]\n",
    "while len(testid) != len(set(testid)):\n",
    "    testid = np.random.randint(0, npdata.shape[0], 10)\n",
    "\n",
    "# Get your testing data\n",
    "print(testid)\n",
    "testset = npdata[testid, :]\n",
    "testtarget = nptarget[testid]\n",
    "print(testset.shape)\n",
    "\n",
    "# Get your training data\n",
    "trainset = np.delete(npdata, testid, 0)\n",
    "traintarget = np.delete(nptarget, testid, 0)\n",
    "print(trainset.shape)\n",
    "\n",
    "# Build model using fit()\n",
    "model = GaussianNB()\n",
    "model.fit(trainset, traintarget)\n",
    "\n",
    "# Apply model to test set using predict()\n",
    "expected = testtarget\n",
    "predicted = model.predict(testset)\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "\n",
    "# Print a confusion matrix (true positive, false positives, etc.)\n",
    "print(metrics.confusion_matrix(expected, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q8: Run the above code several times and observe how the metrics change. Adjust the number of held out examples for testing in line 6. How do these results compare with the results using cross-validation? When the results are quite different, what phenomenon might you be observing?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your answer to Q8 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Rule-based classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class we talked about the difference between classification via learning and classification via rule. Using the most recent train/test split from part 5, develop a rule for distinguishing men from women using the features in the `trainset` data. Apply that rule to the `testset` data to get your `predicted` values. Then evaluate your output using the `metrics.classification_report` function, shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the rule you derived by looking at the training data to the test data,\n",
    "# and store the output in the predicted variable.\n",
    "\n",
    "# Evaluate the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q9: What rule did you use? Did it work better, worse, or the same as your classifiers? (Be sure to compare it to all three classifiers you used.)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your answer to Q9 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verifying and submitting your work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be submitting this Jupyter Notebook to your GitHub repo for this problem set. \n",
    "\n",
    "<span style=\"color: red;\">1. Make sure you've answered every <b>Q</b> question.</span>\n",
    "\n",
    "<span style=\"color: blue;\">2. Make sure you've written code wherever required.</span> \n",
    "\n",
    "<span style=\"color: green;\">3. Go up to the Kernel menu and select Restart and Run All. This will run all of the code you've written. Make sure there are no errors.</span>\n",
    "\n",
    "<span style=\"color: purple;\">4. Commit and push the Jupyter Notebook (<code>ps4_classification.ipynb</code>) to GitHub by 11:59pm on Monday, September 28.</span>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
